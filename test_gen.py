# import torch
# import os

# # é«˜é€ŸåŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨ã‚’å¼·åˆ¶çš„ã«ã‚ªãƒ•ã«ã™ã‚‹è¨­å®š
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"

# from diffusers import StableDiffusionPipeline

# model_id = "runwayml/stable-diffusion-v1-5"

# print("ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...")
# # CPUã¨GPUã®æ©‹æ¸¡ã—ã‚’ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªå½¢ã§è¡Œã†è¨­å®š
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# )
# pipe.to("cuda")

# prompt = "A red apple on the left of a blue cup"

# print("ç”»åƒç”Ÿæˆä¸­...ï¼ˆã“ã®å‡¦ç†ã«ã¯1åˆ†ã»ã©ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰")
# # é«˜åº¦ãªæœ€é©åŒ–ã‚’ä½¿ã‚ãšã«ç”Ÿæˆ
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# image.save("result_test.png")
# print("æˆåŠŸã—ã¾ã—ãŸï¼ result_test.png ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# import torch
# import os
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"
# from diffusers import StableDiffusionPipeline

# model_id = "runwayml/stable-diffusion-v1-5"

# print("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# # ã™ã§ã«ä¸€åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãªã®ã§ã€ã“ã“ã¯ä¸€ç¬ã§çµ‚ã‚ã‚‹ã¯ãšã§ã™
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16, 
#     safety_checker=None
# )
# pipe.to("cuda")

# # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚ˆã‚Šå…·ä½“çš„ã«ã—ã¦ã€AIã®ã€Œç©ºé–“èªè­˜åŠ›ã€ã‚’è©¦ã—ã¾ã™
# prompt = "a professional photo of a bright red apple on the left side of a blue porcelain cup, on a clean white table, studio lighting, 8k"

# print("ç”»åƒç”Ÿæˆä¸­...")
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# # æœ€çµ‚ç¢ºèªç”¨ã®åå‰ã§ä¿å­˜
# image.save("result_final_step.png")
# print("\nğŸ‰ ç”ŸæˆæˆåŠŸï¼")
# print("å·¦å´ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‹ã‚‰ 'result_final_step.png' ã‚’é–‹ã„ã¦ã¿ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"
# from diffusers import StableDiffusionPipeline

# model_id = "runwayml/stable-diffusion-v1-5"

# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16, 
#     safety_checker=None
# )
# pipe.to("cuda")

# print("2. CoMPaSS (SD1.5ç”¨è»½é‡ãƒ‘ãƒƒãƒ) ã‚’é©ç”¨ä¸­...")
# # è‘—è€…ã®ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰SD1.5ç”¨ã®é‡ã¿ã‚’ç›´æ¥æŒ‡å®šã—ã¾ã™
# # â€»ä»Šå›ã¯ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã€ä¿¡é ¼æ€§ã®é«˜ã„HFå…¬å¼å½¢å¼ã§èª­ã¿è¾¼ã¿ã¾ã™
# try:
#     pipe.load_lora_weights("blurryg/CoMPaSS", weight_name="compass_sd15.safetensors")
#     print("CoMPaSSã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸï¼")
# except Exception as e:
#     print(f"LoRAãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
#     print("ãƒªãƒã‚¸ãƒˆãƒªåã‚„ãƒˆãƒ¼ã‚¯ãƒ³è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# # CoMPaSSã®åŠ¹æœãŒå‡ºã‚„ã™ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# # ã€Œå·¦ã«ãƒªãƒ³ã‚´ã€å³ã«ã‚³ãƒƒãƒ—ã€ã¨ã„ã†é…ç½®ã‚’AIã«å¼·ãæ„è­˜ã•ã›ã¾ã™
# prompt = "a red apple on the left, a blue cup on the right, high quality"

# print("3. CoMPaSSã‚’æœ‰åŠ¹ã«ã—ã¦ç”»åƒã‚’ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# image.save("result_with_compass_sd15.png")
# print("\nğŸ‰ ç”ŸæˆæˆåŠŸï¼ 'result_with_compass_sd15.png' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# from diffusers import StableDiffusionPipeline

# # ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã®è¨­å®š
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"

# # ã‚ãªãŸã®Hugging Faceãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã“ã“ã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„
# MY_TOKEN = ""

# model_id = "runwayml/stable-diffusion-v1-5"

# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆSD1.5ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16, 
#     use_auth_token=MY_TOKEN,
#     safety_checker=None
# )
# pipe.to("cuda")

# print("2. CoMPaSS (SD1.5ç”¨) ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»é©ç”¨ä¸­...")
# # è‘—è€…ã®æœ€æ–°ã®ãƒªãƒã‚¸ãƒˆãƒªæ§‹æˆã«åˆã‚ã›ãŸãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™
# # â€»blurgyy/CoMPaSS-FLUX.1 ã¨ã„ã†åå‰ã§ã‚‚SD1.5ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
# try:
#     # è‘—è€…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’ç¢ºèªã—ã€LoRAãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™
#     # ã‚‚ã—ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã¯ã€ã“ã® repo_id ã‚’ README ã«ã‚ã‚‹æ­£ç¢ºãªã‚‚ã®ã«æ›¸ãæ›ãˆã¦ãã ã•ã„
#     pipe.load_lora_weights(
#         "blurgyy/CoMPaSS-FLUX.1", 
#         weight_name="compass_sd15.safetensors",
#         use_auth_token=MY_TOKEN
#     )
#     print("âœ… CoMPaSSã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸï¼")
# except Exception as e:
#     print(f"âŒ LoRAãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
#     print("â€»ã“ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ã€åœŸå°ã®AIã ã‘ã§ç”»åƒç”Ÿæˆã‚’è©¦ã¿ã¾ã™ã€‚")

# prompt = "a red apple on the left, a blue cup on the right, high quality"

# print("3. ç”»åƒã‚’ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# image.save("result_compass_sd15_real.png")
# print("\nğŸ‰ ç”Ÿæˆå®Œäº†ï¼ 'result_compass_sd15_real.png' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# from datetime import datetime
# from diffusers import StableDiffusionPipeline

# # --- è¨­å®š ---
# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# # è©¦ã—ãŸã„ãƒ‘ãƒƒãƒã®æƒ…å ±ï¼ˆSD1.5ç”¨ï¼‰
# PATCH_REPO = "blurgyy/CoMPaSS-FLUX.1"
# PATCH_NAME = "compass_sd15"  # ãƒ‘ãƒƒãƒåã¨ã—ã¦ä½¿ç”¨
# WEIGHT_FILE = "compass_sd15.safetensors"
# # MY_TOKEN = "ã‚ãªãŸã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã“ã“ã«è²¼ã‚‹"
# MY_TOKEN = ""

# # PROMPT = "a red apple on the left, a blue cup on the right"
# PROMPT = "A pink cat on the left of a green dog, 8k"    # å·¦ã«ãƒ”ãƒ³ã‚¯ã®çŒ«ã€å³ã«ç·‘ã®çŠ¬

# # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆï¼ˆå®Ÿè¡Œæ™‚åˆ»ã§åˆ†ã‘ã‚‹ï¼‰
# current_dir = os.path.dirname(os.path.abspath(__file__))
# output_root = os.path.join(current_dir, "outputs")
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = os.path.join(output_root, f"experiment_{timestamp}")

# os.makedirs(output_dir, exist_ok=True)
# print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")

# # --- 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ ---
# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# # --- 2. ãƒ‘ãƒƒãƒãªã— (Before) ã®ç”Ÿæˆ ---
# print("2. [ãƒ‘ãƒƒãƒãªã—] ã§ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     img_no = pipe(PROMPT).images[0]
#     img_no.save(f"{output_dir}/01_base_only.png")

# # --- 3. ãƒ‘ãƒƒãƒã‚ã‚Š (After) ã®ç”Ÿæˆ ---
# print(f"3. [ãƒ‘ãƒƒãƒã‚ã‚Š: {PATCH_NAME}] ã®åˆä½“ã‚’è©¦è¡Œä¸­...")
# try:
#     pipe.load_lora_weights(
#         PATCH_REPO, 
#         weight_name=WEIGHT_FILE,
#         use_auth_token=MY_TOKEN
#     )
#     print("âœ… ãƒ‘ãƒƒãƒã®åˆä½“ã«æˆåŠŸï¼")
    
#     with torch.no_grad():
#         img_with = pipe(PROMPT).images[0]
#         # ãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒ‘ãƒƒãƒåã‚’å…¥ã‚Œã‚‹
#         img_with.save(f"{output_dir}/02_with_{PATCH_NAME}.png")
#     print(f"âœ… ä¿å­˜å®Œäº†: 02_with_{PATCH_NAME}.png")

# except Exception as e:
#     print(f"âŒ ãƒ‘ãƒƒãƒã®é©ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
#     print("â€»ãƒ‘ãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã§ããªã„ãŸã‚ã€æ¯”è¼ƒç”»åƒã¯ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

# print(f"\nå®Ÿé¨“çµ‚äº†ã€‚ãƒ•ã‚©ãƒ«ãƒ€ '{output_dir}' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")



# import torch
# import os
# from datetime import datetime
# from diffusers import StableDiffusionPipeline, UNet2DConditionModel
# from safetensors.torch import load_file

# # --- è¨­å®š ---
# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆåå‰ãŒé•ã†å ´åˆã¯ã“ã“ã‚’æ›¸ãæ›ãˆã¦ãã ã•ã„ï¼‰
# COMPASS_WEIGHTS_PATH = "diffusion_pytorch_model.safetensors"

# PROMPT = "A pink cat on the left of a green dog, 8k"

# # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
# current_dir = os.path.dirname(os.path.abspath(__file__))
# output_root = os.path.join(current_dir, "outputs")
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = os.path.join(output_root, f"experiment_{timestamp}")
# os.makedirs(output_dir, exist_ok=True)

# print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")

# # --- 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ ---
# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# # --- 2. ãƒ‘ãƒƒãƒãªã— (Before) ã®ç”Ÿæˆ ---
# print("2. [CoMPaSSãªã—] ã§ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     img_no = pipe(PROMPT).images[0]
#     img_no.save(f"{output_dir}/01_base_only.png")
# print("âœ… ä¿å­˜å®Œäº†: 01_base_only.png")

# # --- 3. CoMPaSSé‡ã¿ã®æ³¨å…¥ (After) ---
# print(f"3. [CoMPaSSé‡ã¿] ã‚’UNetã«æ³¨å…¥ä¸­...")
# if os.path.exists(COMPASS_WEIGHTS_PATH):
#     try:
#         # safetensorså½¢å¼ã®é‡ã¿ã‚’èª­ã¿è¾¼ã‚€
#         state_dict = load_file(COMPASS_WEIGHTS_PATH)
        
#         # ãƒ¢ãƒ‡ãƒ«ã®å¿ƒè‡“éƒ¨(unet)ã®é‡ã¿ã‚’ã€CoMPaSSã®ã‚‚ã®ã«å·®ã—æ›¿ãˆã‚‹
#         pipe.unet.load_state_dict(state_dict)
#         print("âœ… CoMPaSSé‡ã¿ã®æ³¨å…¥ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        
#         print("4. [CoMPaSSã‚ã‚Š] ã§ç”Ÿæˆä¸­...")
#         with torch.no_grad():
#             img_with = pipe(PROMPT).images[0]
#             img_with.save(f"{output_dir}/02_with_compass.png")
#         print("âœ… ä¿å­˜å®Œäº†: 02_with_compass.png")
        
#     except Exception as e:
#         print(f"âŒ æ³¨å…¥ã‚¨ãƒ©ãƒ¼: {e}")
# else:
#     print(f"âŒ ã‚¨ãƒ©ãƒ¼: {COMPASS_WEIGHTS_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# print(f"\nå®Ÿé¨“çµ‚äº†ã€‚ãƒ•ã‚©ãƒ«ãƒ€ '{output_dir}' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


import torch
import os
from datetime import datetime
from diffusers import StableDiffusionPipeline
from safetensors.torch import load_file

# --- è¨­å®š ---
MODEL_ID = "runwayml/stable-diffusion-v1-5"
COMPASS_WEIGHTS_PATH = "diffusion_pytorch_model.safetensors"
PROMPT = "A pink cat on the left of a green dog, 8k"

# ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
current_dir = os.path.dirname(os.path.abspath(__file__))
output_root = os.path.join(current_dir, "outputs")
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_dir = os.path.join(output_root, f"experiment_{timestamp}")
os.makedirs(output_dir, exist_ok=True)

print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")

# --- 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ ---
print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
pipe = StableDiffusionPipeline.from_pretrained(
    MODEL_ID, 
    torch_dtype=torch.float16,
    safety_checker=None
).to("cuda")

# --- 2. ãƒ‘ãƒƒãƒãªã—ç”Ÿæˆ ---
print("2. [CoMPaSSãªã—] ã§ç”Ÿæˆä¸­...")
with torch.no_grad():
    img_no = pipe(PROMPT).images[0]
    img_no.save(f"{output_dir}/01_base_only.png")
print("âœ… ä¿å­˜å®Œäº†: 01_base_only.png")

# --- 3. CoMPaSSé‡ã¿ã®æ³¨å…¥ ---
print("3. CoMPaSSé‡ã¿ã‚’æ³¨å…¥ä¸­...")
if os.path.exists(COMPASS_WEIGHTS_PATH):
    try:
        # ğŸŒŸ ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã—ãªãŒã‚‰èª­ã¿è¾¼ã‚€è¨­å®š
        state_dict = load_file(COMPASS_WEIGHTS_PATH, device="cuda") 
        
        # UNetã®é‡ã¿ã‚’å·®ã—æ›¿ãˆ
        pipe.unet.load_state_dict(state_dict)
        
        # èª­ã¿è¾¼ã¿çµ‚ã‚ã£ãŸã‚‰ä¸è¦ãªãƒ¡ãƒ¢ãƒªã‚’å³åº§ã«è§£æ”¾
        del state_dict
        torch.cuda.empty_cache()
        
        print("âœ… CoMPaSSã®æ³¨å…¥ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        
        print("4. [CoMPaSSã‚ã‚Š] ã§ç”Ÿæˆä¸­...")
        with torch.no_grad():
            img_with = pipe(PROMPT).images[0]
            img_with.save(f"{output_dir}/02_with_compass.png")
        print("âœ… ä¿å­˜å®Œäº†: 02_with_compass.png")
        
    except Exception as e:
        print(f"âŒ æ³¨å…¥ã‚¨ãƒ©ãƒ¼: {e}")
else:
    print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«æœªå®Œäº† (ç¾åœ¨ã‚µã‚¤ã‚ºã‚’ç¢ºèªã—ã¦ãã ã•ã„)")

print(f"\nå®Ÿé¨“çµ‚äº†ã€‚")