# import torch
# import os

# # é«˜é€ŸåŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨ã‚’å¼·åˆ¶çš„ã«ã‚ªãƒ•ã«ã™ã‚‹è¨­å®š
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"

# from diffusers import StableDiffusionPipeline

# model_id = "runwayml/stable-diffusion-v1-5"

# print("ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...")
# # CPUã¨GPUã®æ©‹æ¸¡ã—ã‚’ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªå½¢ã§è¡Œã†è¨­å®š
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# )
# pipe.to("cuda")

# prompt = "A red apple on the left of a blue cup"

# print("ç”»åƒç”Ÿæˆä¸­...ï¼ˆã“ã®å‡¦ç†ã«ã¯1åˆ†ã»ã©ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰")
# # é«˜åº¦ãªæœ€é©åŒ–ã‚’ä½¿ã‚ãšã«ç”Ÿæˆ
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# image.save("result_test.png")
# print("æˆåŠŸã—ã¾ã—ãŸï¼ result_test.png ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# import torch
# import os
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"
# from diffusers import StableDiffusionPipeline

# model_id = "runwayml/stable-diffusion-v1-5"

# print("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# # ã™ã§ã«ä¸€åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãªã®ã§ã€ã“ã“ã¯ä¸€ç¬ã§çµ‚ã‚ã‚‹ã¯ãšã§ã™
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16, 
#     safety_checker=None
# )
# pipe.to("cuda")

# # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚ˆã‚Šå…·ä½“çš„ã«ã—ã¦ã€AIã®ã€Œç©ºé–“èªè­˜åŠ›ã€ã‚’è©¦ã—ã¾ã™
# prompt = "a professional photo of a bright red apple on the left side of a blue porcelain cup, on a clean white table, studio lighting, 8k"

# print("ç”»åƒç”Ÿæˆä¸­...")
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# # æœ€çµ‚ç¢ºèªç”¨ã®åå‰ã§ä¿å­˜
# image.save("result_final_step.png")
# print("\nğŸ‰ ç”ŸæˆæˆåŠŸï¼")
# print("å·¦å´ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‹ã‚‰ 'result_final_step.png' ã‚’é–‹ã„ã¦ã¿ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"
# from diffusers import StableDiffusionPipeline

# model_id = "runwayml/stable-diffusion-v1-5"

# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16, 
#     safety_checker=None
# )
# pipe.to("cuda")

# print("2. CoMPaSS (SD1.5ç”¨è»½é‡ãƒ‘ãƒƒãƒ) ã‚’é©ç”¨ä¸­...")
# # è‘—è€…ã®ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰SD1.5ç”¨ã®é‡ã¿ã‚’ç›´æ¥æŒ‡å®šã—ã¾ã™
# # â€»ä»Šå›ã¯ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã€ä¿¡é ¼æ€§ã®é«˜ã„HFå…¬å¼å½¢å¼ã§èª­ã¿è¾¼ã¿ã¾ã™
# try:
#     pipe.load_lora_weights("blurryg/CoMPaSS", weight_name="compass_sd15.safetensors")
#     print("CoMPaSSã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸï¼")
# except Exception as e:
#     print(f"LoRAãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
#     print("ãƒªãƒã‚¸ãƒˆãƒªåã‚„ãƒˆãƒ¼ã‚¯ãƒ³è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# # CoMPaSSã®åŠ¹æœãŒå‡ºã‚„ã™ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# # ã€Œå·¦ã«ãƒªãƒ³ã‚´ã€å³ã«ã‚³ãƒƒãƒ—ã€ã¨ã„ã†é…ç½®ã‚’AIã«å¼·ãæ„è­˜ã•ã›ã¾ã™
# prompt = "a red apple on the left, a blue cup on the right, high quality"

# print("3. CoMPaSSã‚’æœ‰åŠ¹ã«ã—ã¦ç”»åƒã‚’ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# image.save("result_with_compass_sd15.png")
# print("\nğŸ‰ ç”ŸæˆæˆåŠŸï¼ 'result_with_compass_sd15.png' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# from diffusers import StableDiffusionPipeline

# # ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã®è¨­å®š
# os.environ["ACCELERATE_USE_XFORMERS"] = "FALSE"

# # ã‚ãªãŸã®Hugging Faceãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã“ã“ã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„
# MY_TOKEN = ""

# model_id = "runwayml/stable-diffusion-v1-5"

# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆSD1.5ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     model_id, 
#     torch_dtype=torch.float16, 
#     use_auth_token=MY_TOKEN,
#     safety_checker=None
# )
# pipe.to("cuda")

# print("2. CoMPaSS (SD1.5ç”¨) ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»é©ç”¨ä¸­...")
# # è‘—è€…ã®æœ€æ–°ã®ãƒªãƒã‚¸ãƒˆãƒªæ§‹æˆã«åˆã‚ã›ãŸãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™
# # â€»blurgyy/CoMPaSS-FLUX.1 ã¨ã„ã†åå‰ã§ã‚‚SD1.5ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
# try:
#     # è‘—è€…ã®ãƒªãƒã‚¸ãƒˆãƒªåã‚’ç¢ºèªã—ã€LoRAãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™
#     # ã‚‚ã—ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã¯ã€ã“ã® repo_id ã‚’ README ã«ã‚ã‚‹æ­£ç¢ºãªã‚‚ã®ã«æ›¸ãæ›ãˆã¦ãã ã•ã„
#     pipe.load_lora_weights(
#         "blurgyy/CoMPaSS-FLUX.1", 
#         weight_name="compass_sd15.safetensors",
#         use_auth_token=MY_TOKEN
#     )
#     print("âœ… CoMPaSSã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸï¼")
# except Exception as e:
#     print(f"âŒ LoRAãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
#     print("â€»ã“ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ã€åœŸå°ã®AIã ã‘ã§ç”»åƒç”Ÿæˆã‚’è©¦ã¿ã¾ã™ã€‚")

# prompt = "a red apple on the left, a blue cup on the right, high quality"

# print("3. ç”»åƒã‚’ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     image = pipe(prompt).images[0]

# image.save("result_compass_sd15_real.png")
# print("\nğŸ‰ ç”Ÿæˆå®Œäº†ï¼ 'result_compass_sd15_real.png' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# from datetime import datetime
# from diffusers import StableDiffusionPipeline

# # --- è¨­å®š ---
# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# # è©¦ã—ãŸã„ãƒ‘ãƒƒãƒã®æƒ…å ±ï¼ˆSD1.5ç”¨ï¼‰
# PATCH_REPO = "blurgyy/CoMPaSS-FLUX.1"
# PATCH_NAME = "compass_sd15"  # ãƒ‘ãƒƒãƒåã¨ã—ã¦ä½¿ç”¨
# WEIGHT_FILE = "compass_sd15.safetensors"
# # MY_TOKEN = "ã‚ãªãŸã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã“ã“ã«è²¼ã‚‹"
# MY_TOKEN = ""

# # PROMPT = "a red apple on the left, a blue cup on the right"
# PROMPT = "A pink cat on the left of a green dog, 8k"    # å·¦ã«ãƒ”ãƒ³ã‚¯ã®çŒ«ã€å³ã«ç·‘ã®çŠ¬

# # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆï¼ˆå®Ÿè¡Œæ™‚åˆ»ã§åˆ†ã‘ã‚‹ï¼‰
# current_dir = os.path.dirname(os.path.abspath(__file__))
# output_root = os.path.join(current_dir, "outputs")
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = os.path.join(output_root, f"experiment_{timestamp}")

# os.makedirs(output_dir, exist_ok=True)
# print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")

# # --- 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ ---
# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# # --- 2. ãƒ‘ãƒƒãƒãªã— (Before) ã®ç”Ÿæˆ ---
# print("2. [ãƒ‘ãƒƒãƒãªã—] ã§ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     img_no = pipe(PROMPT).images[0]
#     img_no.save(f"{output_dir}/01_base_only.png")

# # --- 3. ãƒ‘ãƒƒãƒã‚ã‚Š (After) ã®ç”Ÿæˆ ---
# print(f"3. [ãƒ‘ãƒƒãƒã‚ã‚Š: {PATCH_NAME}] ã®åˆä½“ã‚’è©¦è¡Œä¸­...")
# try:
#     pipe.load_lora_weights(
#         PATCH_REPO, 
#         weight_name=WEIGHT_FILE,
#         use_auth_token=MY_TOKEN
#     )
#     print("âœ… ãƒ‘ãƒƒãƒã®åˆä½“ã«æˆåŠŸï¼")
    
#     with torch.no_grad():
#         img_with = pipe(PROMPT).images[0]
#         # ãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒ‘ãƒƒãƒåã‚’å…¥ã‚Œã‚‹
#         img_with.save(f"{output_dir}/02_with_{PATCH_NAME}.png")
#     print(f"âœ… ä¿å­˜å®Œäº†: 02_with_{PATCH_NAME}.png")

# except Exception as e:
#     print(f"âŒ ãƒ‘ãƒƒãƒã®é©ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
#     print("â€»ãƒ‘ãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã§ããªã„ãŸã‚ã€æ¯”è¼ƒç”»åƒã¯ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

# print(f"\nå®Ÿé¨“çµ‚äº†ã€‚ãƒ•ã‚©ãƒ«ãƒ€ '{output_dir}' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")



# import torch
# import os
# from datetime import datetime
# from diffusers import StableDiffusionPipeline, UNet2DConditionModel
# from safetensors.torch import load_file

# # --- è¨­å®š ---
# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆåå‰ãŒé•ã†å ´åˆã¯ã“ã“ã‚’æ›¸ãæ›ãˆã¦ãã ã•ã„ï¼‰
# COMPASS_WEIGHTS_PATH = "diffusion_pytorch_model.safetensors"

# PROMPT = "A pink cat on the left of a green dog, 8k"

# # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
# current_dir = os.path.dirname(os.path.abspath(__file__))
# output_root = os.path.join(current_dir, "outputs")
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = os.path.join(output_root, f"experiment_{timestamp}")
# os.makedirs(output_dir, exist_ok=True)

# print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")

# # --- 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ ---
# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# # --- 2. ãƒ‘ãƒƒãƒãªã— (Before) ã®ç”Ÿæˆ ---
# print("2. [CoMPaSSãªã—] ã§ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     img_no = pipe(PROMPT).images[0]
#     img_no.save(f"{output_dir}/01_base_only.png")
# print("âœ… ä¿å­˜å®Œäº†: 01_base_only.png")

# # --- 3. CoMPaSSé‡ã¿ã®æ³¨å…¥ (After) ---
# print(f"3. [CoMPaSSé‡ã¿] ã‚’UNetã«æ³¨å…¥ä¸­...")
# if os.path.exists(COMPASS_WEIGHTS_PATH):
#     try:
#         # safetensorså½¢å¼ã®é‡ã¿ã‚’èª­ã¿è¾¼ã‚€
#         state_dict = load_file(COMPASS_WEIGHTS_PATH)
        
#         # ãƒ¢ãƒ‡ãƒ«ã®å¿ƒè‡“éƒ¨(unet)ã®é‡ã¿ã‚’ã€CoMPaSSã®ã‚‚ã®ã«å·®ã—æ›¿ãˆã‚‹
#         pipe.unet.load_state_dict(state_dict)
#         print("âœ… CoMPaSSé‡ã¿ã®æ³¨å…¥ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        
#         print("4. [CoMPaSSã‚ã‚Š] ã§ç”Ÿæˆä¸­...")
#         with torch.no_grad():
#             img_with = pipe(PROMPT).images[0]
#             img_with.save(f"{output_dir}/02_with_compass.png")
#         print("âœ… ä¿å­˜å®Œäº†: 02_with_compass.png")
        
#     except Exception as e:
#         print(f"âŒ æ³¨å…¥ã‚¨ãƒ©ãƒ¼: {e}")
# else:
#     print(f"âŒ ã‚¨ãƒ©ãƒ¼: {COMPASS_WEIGHTS_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# print(f"\nå®Ÿé¨“çµ‚äº†ã€‚ãƒ•ã‚©ãƒ«ãƒ€ '{output_dir}' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# from datetime import datetime
# from diffusers import StableDiffusionPipeline
# from safetensors.torch import load_file

# # --- è¨­å®š ---
# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# COMPASS_WEIGHTS_PATH = "diffusion_pytorch_model.safetensors"
# PROMPT = "A pink cat on the left of a green dog, 8k"

# # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
# current_dir = os.path.dirname(os.path.abspath(__file__))
# output_root = os.path.join(current_dir, "outputs")
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = os.path.join(output_root, f"experiment_{timestamp}")
# os.makedirs(output_dir, exist_ok=True)

# print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")

# # --- 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ ---
# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# # --- 2. ãƒ‘ãƒƒãƒãªã—ç”Ÿæˆ ---
# print("2. [CoMPaSSãªã—] ã§ç”Ÿæˆä¸­...")
# with torch.no_grad():
#     img_no = pipe(PROMPT).images[0]
#     img_no.save(f"{output_dir}/01_base_only.png")
# print("âœ… ä¿å­˜å®Œäº†: 01_base_only.png")

# # --- 3. CoMPaSSé‡ã¿ã®æ³¨å…¥ ---
# print("3. CoMPaSSé‡ã¿ã‚’æ³¨å…¥ä¸­...")
# if os.path.exists(COMPASS_WEIGHTS_PATH):
#     try:
#         # ğŸŒŸ ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã—ãªãŒã‚‰èª­ã¿è¾¼ã‚€è¨­å®š
#         state_dict = load_file(COMPASS_WEIGHTS_PATH, device="cuda") 
        
#         # UNetã®é‡ã¿ã‚’å·®ã—æ›¿ãˆ
#         pipe.unet.load_state_dict(state_dict)
        
#         # èª­ã¿è¾¼ã¿çµ‚ã‚ã£ãŸã‚‰ä¸è¦ãªãƒ¡ãƒ¢ãƒªã‚’å³åº§ã«è§£æ”¾
#         del state_dict
#         torch.cuda.empty_cache()
        
#         print("âœ… CoMPaSSã®æ³¨å…¥ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        
#         print("4. [CoMPaSSã‚ã‚Š] ã§ç”Ÿæˆä¸­...")
#         with torch.no_grad():
#             img_with = pipe(PROMPT).images[0]
#             img_with.save(f"{output_dir}/02_with_compass.png")
#         print("âœ… ä¿å­˜å®Œäº†: 02_with_compass.png")
        
#     except Exception as e:
#         print(f"âŒ æ³¨å…¥ã‚¨ãƒ©ãƒ¼: {e}")
# else:
#     print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«æœªå®Œäº† (ç¾åœ¨ã‚µã‚¤ã‚ºã‚’ç¢ºèªã—ã¦ãã ã•ã„)")

# print(f"\nå®Ÿé¨“çµ‚äº†ã€‚")


# import torch
# import os
# from datetime import datetime
# from diffusers import StableDiffusionPipeline
# from safetensors.torch import load_file

# # --- 1. è¨­å®šã‚¨ãƒªã‚¢ ---
# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# COMPASS_WEIGHTS_PATH = "diffusion_pytorch_model.safetensors"

# # è«–æ–‡ã®è©•ä¾¡ï¼ˆFigure 5ãªã©ï¼‰ã«åŸºã¥ã„ãŸã€Œç©ºé–“é–¢ä¿‚ã‚’å«ã‚€ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# # åº§æ¨™æŒ‡å®šã¯è¡Œã‚ãšã€æ–‡ç« ã®ã¿ã§é…ç½®ã‚’æŒ‡ç¤ºã—ã¾ã™
# # ä¾‹ï¼šå·¦ã«ã€Œé’ã„è»Šã€ã€å³ã«ã€Œèµ¤ã„ãƒã‚¤ã‚¯ã€ã‚’ç½®ããŸã„å ´åˆ
# PROMPT = "a blue car on the left, a red motorcycle on the right"

# # å‡ºåŠ›è¨­å®š
# current_dir = os.path.dirname(os.path.abspath(__file__))
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = os.path.join(current_dir, "outputs", f"compass_eval_{timestamp}")
# os.makedirs(output_dir, exist_ok=True)

# # --- 2. æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã¨ç”Ÿæˆ ---
# print("1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# print("2. [æ¨™æº–SD1.5] ã§ç”Ÿæˆä¸­... (æ–‡ç« ã®æŒ‡ç¤ºã«å¾“ãˆã‚‹ã‹ç¢ºèª)")
# with torch.no_grad():
#     # æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã¯ã€Œleft ofã€ãªã©ã®é †åºæƒ…å ±ã®è§£é‡ˆãŒè‹¦æ‰‹ã§ã™
#     img_std = pipe(PROMPT).images[0]
#     img_std.save(os.path.join(output_dir, "01_standard_sd.png"))

# # --- 3. CoMPaSSé‡ã¿ã®æ³¨å…¥ ---
# print("3. CoMPaSSé‡ã¿ã‚’æ³¨å…¥ä¸­...")
# if not os.path.exists(COMPASS_WEIGHTS_PATH):
#     raise FileNotFoundError(f"ã‚¨ãƒ©ãƒ¼: {COMPASS_WEIGHTS_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# # è«–æ–‡ã®æ‰‹æ³•ãŒå­¦ç¿’ã•ã‚ŒãŸUNetã®é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰
# state_dict = load_file(COMPASS_WEIGHTS_PATH, device="cuda")
# pipe.unet.load_state_dict(state_dict)
# del state_dict
# torch.cuda.empty_cache()

# # --- 4. CoMPaSSã§ã®ç”Ÿæˆ ---
# print("4. [CoMPaSSé©ç”¨æ¸ˆã¿] ã§ç”Ÿæˆä¸­... (TENORåŠ¹æœã®ç¢ºèª)")
# with torch.no_grad():
#     # å…¨ãåŒã˜æ–‡ç« ã‚’æŠ•ã’ã¾ã™ãŒã€ä¸­èº«ã®UNetãŒãƒˆãƒ¼ã‚¯ãƒ³é †åº(TENOR)ã‚’
#     # è€ƒæ…®ã—ã¦è¨ˆç®—ã™ã‚‹ãŸã‚ã€é…ç½®ã®æ­£ç¢ºã•ãŒå‘ä¸Šã—ã¾ã™
#     img_compass = pipe(PROMPT).images[0]
#     img_compass.save(os.path.join(output_dir, "02_compass_enhanced.png"))

# print(f"\nâœ… å®Ÿé¨“å®Œäº†ï¼")
# print(f"å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")
# print(f"æ¯”è¼ƒãƒã‚¤ãƒ³ãƒˆ: å·¦ã«é¦¬ã€å³ã«èŠ±ç“¶ãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# import torch
# import os
# import requests
# from datetime import datetime
# from diffusers import StableDiffusionPipeline
# from safetensors.torch import load_file
# from openai import OpenAI
# from dotenv import load_dotenv  # .envèª­ã¿è¾¼ã¿ç”¨

# # ==========================================
# # 1. ç’°å¢ƒæº–å‚™ã¨è¨­å®š
# # ==========================================
# # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
# load_dotenv()

# # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆè‡ªå‹•çš„ã«ç’°å¢ƒå¤‰æ•°ã®ã‚­ãƒ¼ãŒä½¿ç”¨ã•ã‚Œã¾ã™ï¼‰
# client = OpenAI()

# MODEL_ID = "runwayml/stable-diffusion-v1-5"
# COMPASS_WEIGHTS_PATH = "diffusion_pytorch_model.safetensors"

# # è«–æ–‡ã®è©•ä¾¡æŒ‡æ¨™ï¼ˆVISORï¼‰ã«åŸºã¥ãã€å·¦å³ã®ç©ºé–“é–¢ä¿‚ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# PROMPT = "a blue car on the left, a red motorcycle on the right, photorealistic, 8k"

# # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# output_dir = f"outputs/compass_comparison_{timestamp}"
# os.makedirs(output_dir, exist_ok=True)

# # ==========================================
# # 2. ã€æ¯”è¼ƒå¯¾è±¡ 1ã€‘æ¨™æº–SD1.5
# # ==========================================
# print(f"\n[1/3] æ¨™æº–SD1.5ã‚’ç”Ÿæˆä¸­...")
# pipe = StableDiffusionPipeline.from_pretrained(
#     MODEL_ID, 
#     torch_dtype=torch.float16,
#     safety_checker=None
# ).to("cuda")

# with torch.no_grad():
#     # æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã®ç©ºé–“æ­£ç¢ºæ€§ï¼ˆVISORï¼‰ã¯è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã§17.58%ã¨ã•ã‚Œã¦ã„ã¾ã™
#     img_std = pipe(PROMPT).images[0]
#     img_std.save(os.path.join(output_dir, "01_standard_sd15.png"))
#     print(f"âœ… ä¿å­˜å®Œäº†: 01_standard_sd15.png")

# # ==========================================
# # 3. ã€æ¯”è¼ƒå¯¾è±¡ 2ã€‘SD1.5 + CoMPaSS
# # ==========================================
# print(f"\n[2/3] CoMPaSSé‡ã¿ã‚’æ³¨å…¥ã—ã¦ç”Ÿæˆä¸­...")
# if not os.path.exists(COMPASS_WEIGHTS_PATH):
#     raise FileNotFoundError(f"{COMPASS_WEIGHTS_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# # TENORãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨SCOPãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚ŒãŸUNeté‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰
# state_dict = load_file(COMPASS_WEIGHTS_PATH, device="cuda")
# pipe.unet.load_state_dict(state_dict)
# del state_dict
# torch.cuda.empty_cache()

# with torch.no_grad():
#     # CoMPaSSé©ç”¨ãƒ¢ãƒ‡ãƒ«ã®ç©ºé–“æ­£ç¢ºæ€§ã¯è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã§93.43%ï¼ˆcond.ï¼‰ã«å‘ä¸Šã—ã¾ã™
#     img_compass = pipe(PROMPT).images[0]
#     img_compass.save(os.path.join(output_dir, "02_compass_enhanced.png"))
#     print(f"âœ… ä¿å­˜å®Œäº†: 02_compass_enhanced.png")

# # ==========================================
# # 4. ã€æ¯”è¼ƒå¯¾è±¡ 3ã€‘ChatGPT (DALL-E 3)
# # ==========================================
# print(f"\n[3/3] OpenAI DALL-E 3 APIã‚’å‘¼ã³å‡ºã—ä¸­...")
# try:
#     response = client.images.generate(
#         model="dall-e-3",
#         prompt=PROMPT,
#         size="1024x1024",
#         quality="standard",
#         n=1,
#     )
    
#     image_url = response.data[0].url
#     image_data = requests.get(image_url).content
    
#     with open(os.path.join(output_dir, "03_chatgpt_dalle3.png"), "wb") as f:
#         f.write(image_data)
#     print(f"âœ… ä¿å­˜å®Œäº†: 03_chatgpt_dalle3.png")

# except Exception as e:
#     print(f"âŒ OpenAI APIã‚¨ãƒ©ãƒ¼: {e}")

# # ==========================================
# # 5. å®Œäº†
# # ==========================================
# print(f"\n" + "="*50)
# print(f"æ¯”è¼ƒç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
# print(f"ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")
# print("="*50)



import torch
from diffusers import FluxPipeline

# ãƒ•ãƒ«æ§‹æˆã®ãƒªãƒã‚¸ãƒˆãƒªã‚’æŒ‡å®š
model_id = "black-forest-labs/FLUX.1-dev" 

print("ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’NF4é‡å­åŒ–ã§ãƒ­ãƒ¼ãƒ‰ä¸­...")
pipe = FluxPipeline.from_pretrained(
    model_id,
    # ã“ã“ã§é‡å­åŒ–(4bit)ã‚’ç›´æ¥æŒ‡å®šã™ã‚‹ã“ã¨ã§å®¹é‡ã‚’ç¯€ç´„
    load_in_4bit=True,
    torch_dtype=torch.bfloat16,
    device_map="cuda"
)

# 2. ã‚ãªãŸãŒè¦‹ã¤ã‘ãŸCoMPaSSé‡ã¿ï¼ˆ52.7MBï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰
# ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦é©ç”¨ã—ã¾ã™
print("CoMPaSSé‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... (52.7MB)")
pipe.load_lora_weights(
    "blurgy/CoMPaSS-FLUX.1", 
    weight_name="lora.safetensors",
    adapter_name="compass"
)

# 3. ç”»åƒç”Ÿæˆ
prompt = "a blue car on the left, a red motorcycle on the right, photorealistic, 8k"

print("ç”»åƒã‚’ç”Ÿæˆä¸­...")
image = pipe(
    prompt,
    num_inference_steps=25, # FLUXæ¨å¥¨ã‚¹ãƒ†ãƒƒãƒ—æ•°
    guidance_scale=3.5,
    width=1024,
    height=1024
).images[0]

image.save("flux_compass_result.jpg")
print("ä¿å­˜å®Œäº†: flux_compass_result.jpg")